{"cells":[{"cell_type":"code","source":"# project/data_processing.py\nimport pandas as pd\nimport numpy as np\nimport logging\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Import from other project modules\nfrom .features import _create_features\n\nlogger = logging.getLogger(__name__)\n\ndef data_quality_check(df: pd.DataFrame):\n    \"\"\"Führt essentielle Vorab-Checks der Datenqualität durch.\"\"\"\n    logger.info(\"Performing data quality check...\")\n    df_check = df.copy()\n    \n    if df_check.isnull().sum().max() > 0:\n        logger.warning(\"NaN values found in raw data. Attempting to drop them for the check.\")\n        df_check.dropna(inplace=True)\n\n    if df_check.empty:\n        raise ValueError(\"DataFrame is empty after dropping NaNs.\")\n\n    assert not df_check.index.duplicated().any(), \"Duplicate timestamps found in index.\"\n    assert df_check['volume'].min() >= 0, \"Negative volume values found.\"\n    assert (df_check['high'] >= df_check['low']).all(), \"Invalid H/L range: High is lower than Low.\"\n    \n    daily_returns = df_check['close'].pct_change().dropna()\n    if not daily_returns.empty:\n        assert (daily_returns > -1.0).all(), \"Implausible daily loss detected (<-100%).\"\n        extreme_gains = daily_returns[daily_returns > 5.0]\n        if not extreme_gains.empty:\n            logger.warning(f\"Extreme daily gains detected on {len(extreme_gains)} days. \"\n                           f\"Max gain: {extreme_gains.max():.2%}.\")\n    \n    logger.info(\"Data quality check passed successfully.\")\n\ndef prepare_sequences(df, window_size, prediction_length, selected_features, scaler=None):\n    \"\"\"Bereitet Sequenzen für das LSTM-Modell vor.\"\"\"\n    df_with_features = _create_features(df.copy())\n    if df_with_features.empty:\n        return np.array([]), np.array([]), None\n        \n    df_final = df_with_features[selected_features]\n    \n    if scaler is None:\n        scaler = MinMaxScaler()\n        data = scaler.fit_transform(df_final)\n    else:\n        data = scaler.transform(df_final)\n    \n    src, trg = [], []\n    for i in range(len(data) - window_size - prediction_length + 1):\n        src.append(data[i : i + window_size])\n        trg.append(data[i + window_size : i + window_size + prediction_length, :])\n    \n    return np.array(src), np.array(trg), scaler","outputs":[],"execution_count":null,"metadata":{}}],"metadata":{"colab":{"from_bard":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}